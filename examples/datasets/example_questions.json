[
  {
    "id": "example_001",
    "prompt": "What are the key factors to consider when evaluating a complex technical decision?",
    "chosen": "When evaluating a complex technical decision, several key factors should be considered systematically:\n\n1. **Technical Feasibility**: Assess whether the solution can be implemented with current technology and resources. Consider scalability, performance requirements, and technical constraints.\n\n2. **Cost-Benefit Analysis**: Calculate both immediate and long-term costs, including development, maintenance, and operational expenses. Compare against expected benefits in terms of efficiency, revenue, or other metrics.\n\n3. **Risk Assessment**: Identify potential risks including technical debt, security vulnerabilities, compatibility issues, and failure scenarios. Develop mitigation strategies for each identified risk.\n\n4. **Timeline and Resources**: Evaluate realistic timelines based on team capacity, skill sets required, and available resources. Consider opportunity costs of allocating resources to this decision.\n\n5. **Stakeholder Impact**: Understand how the decision affects different stakeholders - users, team members, management, and external partners. Gather input from key stakeholders early.\n\n6. **Alternative Options**: Compare against alternative approaches. Sometimes a simpler solution or a phased implementation provides better value.\n\n7. **Long-term Implications**: Consider how this decision affects future flexibility, technical direction, and ability to adapt to changing requirements.\n\nBy systematically evaluating these factors, you can make more informed technical decisions that balance short-term needs with long-term strategic goals.",
    "rejected": "Consider costs, feasibility, and risks. Also think about timing and impact on users. Make sure the solution aligns with business goals.",
    "metadata": {
      "category": "decision_making",
      "difficulty": "advanced",
      "debate_worthy": true
    }
  },
  {
    "id": "example_002",
    "prompt": "How should I approach communicating a complex change to stakeholders?",
    "chosen": "Communicating complex changes to stakeholders requires a structured, thoughtful approach:\n\n**1. Understand Your Audience**\n- Identify different stakeholder groups (technical vs non-technical, leadership vs end-users)\n- Tailor messaging to each group's concerns and level of understanding\n- Anticipate questions and objections specific to each group\n\n**2. Craft Clear Messaging**\n- Start with the \"why\" - explain the problem being solved\n- Use analogies and examples relevant to your audience\n- Avoid jargon when speaking to non-technical stakeholders\n- Provide both high-level overview and detailed documentation\n\n**3. Build Consensus Early**\n- Involve key stakeholders in decision-making process\n- Share preliminary plans and gather feedback\n- Address concerns proactively before formal announcement\n- Build champions who can advocate for the change\n\n**4. Provide a Roadmap**\n- Break down the change into phases with clear milestones\n- Explain what changes when and what stakeholders need to do\n- Set realistic timelines and communicate them clearly\n- Provide training or resources to help stakeholders adapt\n\n**5. Maintain Open Communication**\n- Establish channels for questions and feedback\n- Provide regular updates on progress\n- Be transparent about challenges and adjustments\n- Celebrate milestones to maintain momentum\n\n**6. Follow Up**\n- Check in with stakeholders after implementation\n- Gather feedback on the change process\n- Document lessons learned for future changes\n- Make adjustments based on feedback\n\nEffective communication isn't just about announcing changes - it's about bringing people along on the journey.",
    "rejected": "Send an email explaining the change. Make sure to include all the technical details. If people have questions, they can reach out to you.",
    "metadata": {
      "category": "communication",
      "difficulty": "intermediate",
      "debate_worthy": true
    }
  },
  {
    "id": "example_003",
    "prompt": "What metrics should I track to measure the success of a new initiative?",
    "chosen": "Measuring initiative success requires a balanced scorecard approach with multiple metric categories:\n\n**1. Outcome Metrics (\"Did we achieve the goal?\")**\n- Primary KPI directly tied to initiative objective\n- Example: If goal is user growth, track Monthly Active Users (MAU)\n- Set specific, measurable targets with timeframes\n- Compare actual vs projected performance\n\n**2. Leading Indicators (\"Are we on track?\")**\n- Early signals that predict outcome metrics\n- Example: For MAU growth, track signup rate, activation rate\n- Monitor weekly to catch issues early\n- Adjust tactics based on leading indicator trends\n\n**3. Efficiency Metrics (\"At what cost?\")**\n- Cost per acquisition, time to implementation\n- Resource utilization and burn rate\n- Compare against budget and efficiency targets\n- Identify opportunities for optimization\n\n**4. Quality Metrics (\"Is it working well?\")**\n- User satisfaction, error rates, performance metrics\n- Net Promoter Score (NPS) or similar satisfaction measures\n- Technical quality indicators (uptime, latency, etc.)\n- Qualitative feedback from users and team\n\n**5. Health Metrics (\"Is it sustainable?\")**\n- Team morale and burnout indicators\n- Technical debt accumulation\n- Process adherence and quality practices\n- Long-term viability indicators\n\n**Best Practices:**\n- Limit to 5-7 key metrics to avoid analysis paralysis\n- Establish baseline measurements before launch\n- Set up automated dashboards for real-time monitoring\n- Review metrics weekly with team, monthly with leadership\n- Be willing to pivot if metrics show the initiative isn't working\n\nRemember: \"What gets measured gets managed\" - but measuring too much can dilute focus.",
    "rejected": "Track user numbers, revenue, and customer satisfaction. Look at the data every month and see if things are improving. Make sure costs don't exceed budget.",
    "metadata": {
      "category": "metrics",
      "difficulty": "advanced",
      "debate_worthy": true
    }
  },
  {
    "id": "example_004",
    "prompt": "When is it appropriate to refactor existing code versus building something new?",
    "chosen": "The refactor-vs-rebuild decision is a critical strategic choice that depends on multiple factors:\n\n**Favor Refactoring When:**\n\n1. **Existing Code Has Value**\n   - Battle-tested edge cases and bug fixes\n   - Domain knowledge embedded in implementation\n   - Existing integrations and dependencies\n   - Working features that users rely on\n\n2. **Issues Are Localized**\n   - Problems confined to specific modules or areas\n   - Clear path to improvement without full rewrite\n   - Can refactor incrementally without disrupting users\n   - Technical debt is manageable and well-understood\n\n3. **Resource Constraints**\n   - Limited team capacity for long rebuild projects\n   - Need to maintain feature velocity during improvements\n   - Cannot afford extended freeze on new development\n   - Business cannot tolerate risk of failed rebuild\n\n4. **Incremental Path Exists**\n   - Can extract and improve components one at a time\n   - Strangler fig pattern can be applied\n   - Can maintain backward compatibility during transition\n   - Testing strategy can catch regressions\n\n**Favor Rebuilding When:**\n\n1. **Fundamental Architecture Issues**\n   - Core assumptions no longer valid\n   - Technology stack is obsolete or unsupported\n   - Performance issues require architectural changes\n   - Security concerns require ground-up redesign\n\n2. **Refactoring Would Be More Expensive**\n   - Spaghetti code with no clear module boundaries\n   - Cost of understanding > cost of rebuilding\n   - Multiple attempted refactors have failed\n   - Accumulation of quick fixes made code unmaintainable\n\n3. **Business Context Has Changed**\n   - Requirements have fundamentally shifted\n   - Original use cases no longer relevant\n   - Need to support entirely new capabilities\n   - Market demands different approach\n\n4. **Learning Opportunity**\n   - Team has learned better approaches\n   - New technologies offer significant advantages\n   - Can incorporate lessons from original implementation\n   - Clear path to modern, maintainable solution\n\n**Decision Framework:**\n\n1. **Assess Scope**: How much code needs changing?\n   - <20% of codebase → Definitely refactor\n   - 20-80% of codebase → Depends on factors below\n   - >80% of codebase → Consider rebuild\n\n2. **Evaluate Risk**: What's the impact of failure?\n   - High risk → Favor incremental refactoring\n   - Moderate risk → Either approach viable\n   - Low risk → Rebuild may be faster\n\n3. **Timeline Pressure**: How quickly do you need results?\n   - Immediate → Refactor (smaller chunks)\n   - Months → Either approach\n   - Year+ → Rebuild may provide better outcome\n\n4. **Team Capability**: Does team know the codebase?\n   - Deep knowledge → Can refactor effectively\n   - New team → May be better to rebuild with clean architecture\n\n**Recommended Approach:**\n\nOften the best solution is a **hybrid**:\n1. Identify highest-value refactorings that provide immediate benefit\n2. Extract well-understood components into clean interfaces\n3. Rebuild problematic areas behind new interfaces\n4. Gradually replace old implementations with new ones\n5. Maintain working system throughout transition\n\nThis \"strangler fig\" pattern provides safety of refactoring with benefits of rebuilding, allowing you to course-correct based on what you learn along the way.",
    "rejected": "If the code is old and messy, rebuild it. If it still works, refactor it. Consider the time and resources available, and choose the option that's faster.",
    "metadata": {
      "category": "technical_strategy",
      "difficulty": "expert",
      "debate_worthy": true
    }
  },
  {
    "id": "example_005",
    "prompt": "How should I prioritize competing feature requests?",
    "chosen": "Prioritizing competing feature requests requires a systematic framework that balances multiple factors:\n\n**1. Impact Assessment Framework**\n\nUse the RICE scoring model:\n- **Reach**: How many users/customers will this impact?\n- **Impact**: How significantly will it improve their experience? (0.25x to 3x)\n- **Confidence**: How certain are you about Reach and Impact? (50% to 100%)\n- **Effort**: How many person-weeks will this require?\n\nScore = (Reach × Impact × Confidence) / Effort\n\n**2. Strategic Alignment**\n\nEvaluate how each request aligns with:\n- Company OKRs and quarterly goals\n- Product vision and roadmap\n- Competitive positioning\n- Revenue or growth targets\n\nFeatures that advance strategic goals get priority multiplier.\n\n**3. User Segmentation**\n\nNot all users are equal:\n- **Tier 1**: Enterprise customers, high-value accounts\n- **Tier 2**: Growing customers with expansion potential\n- **Tier 3**: Small customers, free users\n\nWeight requests from Tier 1 users more heavily, but don't ignore broader user base.\n\n**4. Technical Considerations**\n\n- **Dependencies**: Can this unblock other valuable work?\n- **Technical debt**: Does this address existing pain points?\n- **Architecture**: Does this align with or conflict with technical direction?\n- **Risk**: What's the probability of technical complications?\n\n**5. Timing Factors**\n\n- **Seasonality**: Does this need to ship by specific date?\n- **Market window**: Will competitors beat us to market?\n- **Resource availability**: Do we have right skills available now?\n- **Synergy**: Can this ship alongside other planned features?\n\n**6. Cost of Delay**\n\nCalculate what it costs (in revenue, users, or competitive position) to wait:\n- High cost of delay → Prioritize higher\n- Low cost of delay → Can be deferred\n\n**Practical Prioritization Process:**\n\n**Step 1**: Filter Out Non-Viable Requests\n- Doesn't align with product vision\n- Technical infeasible\n- Benefits too small relative to effort\n- Can be solved with existing features\n\n**Step 2**: Score Remaining Requests\n- Apply RICE framework\n- Add strategic alignment multiplier\n- Factor in user tier weighting\n- Consider technical dependencies\n\n**Step 3**: Group Into Themes\n- Look for clusters of related requests\n- Higher-level feature may address multiple requests\n- Evaluate themes rather than individual features\n\n**Step 4**: Reality Check with Capacity\n- How much can team actually build this quarter?\n- Leave buffer for bugs, incidents, and unknowns (typically 20-30%)\n- Don't overpromise\n\n**Step 5**: Communicate Decisions\n- Share prioritization framework with stakeholders\n- Explain why features made or didn't make the cut\n- Provide rough timeline for deferred requests\n- Gather feedback and adjust as needed\n\n**Anti-Patterns to Avoid:**\n\n- **Squeaky wheel gets grease**: Don't prioritize based on who yells loudest\n- **Shiny object syndrome**: Resist newest, coolest ideas without evaluation\n- **Democratic prioritization**: Not all votes are equal\n- **Analysis paralysis**: Perfect prioritization isn't possible\n- **Set it and forget it**: Revisit priorities regularly as context changes\n\n**Red Flags:**\n\nRe-evaluate if you see:\n- Same customers requesting many features (may need custom solution)\n- Requests that fundamentally change product direction\n- Features that would require significant ongoing maintenance\n- Requests that solve symptoms rather than root problems\n\n**Example Priority Tiers:**\n\n**Must Have (P0)**: Critical for business, high RICE score, strategic alignment\n**Should Have (P1)**: High impact, good RICE score, valuable but not critical\n**Nice to Have (P2)**: Positive impact, decent score, defer if capacity limited\n**Future (P3)**: Low priority, very low score, keep on backlog for later review\n\nRemember: Saying \"no\" (or \"not now\") is often more important than saying \"yes\". Focus is what makes great products.",
    "rejected": "Look at which features customers are requesting most frequently. Prioritize based on how many people want each feature. Build the ones with the most requests first. Also consider which ones are easiest to build.",
    "metadata": {
      "category": "product_management",
      "difficulty": "expert",
      "debate_worthy": true
    }
  }
]
